<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>信息检索基础概述 | Xinrui Zhang</title>

  
  <meta name="author" content="Xinrui Zhang">
  

  
  <meta name="description" content="本文将根据 elastic search 的原理，按照信息检索的一般流程对信息检索进行简要的介绍，旨在从较高层面了解大致流程，不会深入细节和具体实现。
数据采集这一步是为后续的检索提供用于搜索的语料数据，并做预先的处理。

使用爬虫相关技术收集所需数据

数据清洗

去除空数据
去除重复数据
去除明">
  

  
  
  <meta name="keywords" content="">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="信息检索基础概述"/>

  <meta property="og:site_name" content="Xinrui Zhang"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Xinrui Zhang" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">Xinrui Zhang</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>信息检索基础概述</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2021/08/13/信息检索基础概述/" rel="bookmark">
        <time class="entry-date published" datetime="2021-08-13T09:04:38.000Z">
          2021-08-13
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>本文将根据 elastic search 的原理，按照信息检索的一般流程对信息检索进行简要的介绍，旨在从较高层面了解大致流程，不会深入细节和具体实现。</p>
<h1 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h1><p>这一步是为后续的检索提供用于搜索的语料数据，并做预先的处理。</p>
<ol>
<li><p>使用爬虫相关技术收集所需数据</p>
</li>
<li><p>数据清洗</p>
<ul>
<li>去除空数据</li>
<li>去除重复数据</li>
<li>去除明显错误的数据</li>
</ul>
</li>
<li><p>构建停词表、叙词表</p>
<ul>
<li><p>停词表</p>
<p>无意义的标点、符号、字词等</p>
<p><a target="_blank" rel="noopener" href="https://github.com/goto456/stopwords">中文常用停词表</a></p>
</li>
<li><p>叙词表</p>


<p>主要为同义词表</p>
</li>
</ul>
</li>
<li><p>中文分词</p>
<p>由于中文没有自然的分隔符，相较于英文分词，难度更大，更易产生歧义，常使用字典、隐马尔可夫模型、机器学习等方法，不是本文的重点，故不做具体介绍。</p>
</li>
</ol>
<h1 id="建立倒排索引"><a href="#建立倒排索引" class="headerlink" title="建立倒排索引"></a>建立倒排索引</h1><p>倒排索引是实现高效索引的关键，经过分词处理后得到的项作为 term 项，每项对应其所在文档编号的 postings list 倒排索引，如下图(例子中为方便举例，直接划分至字，没有进行分词)</p>


<p>同时，为了更高效地对 term 项进行检索，elastic search 采取了<a target="_blank" rel="noopener" href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/">FST</a>的结构，FST(Finite State Transducer)类似于 TRIE 树的结构，各 term 项可共用相同的前缀或后缀，但不同的 term 项到达结尾计算到的数值不同。</p>


<p>下图即为完整的 term dict index 词典索引树、term dict 词典、invert index 倒排索引的大致结构。</p>


<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>对于大规模的信息检索，其数据量往往会达到十分庞大的程度，此时能否高效地存取也是影响检索效率的一个重要因素。针对这一问题，elastic search 采取了下列两种方法进行磁盘压缩存储与缓存查询优化。</p>
<ol>
<li><p>Frame of Reference</p>
<p>此方法流程如下图，首先将文档列表处理为增量列表，然后将其划分为大小为 256 的块，然后进行按需分配，这里每块的第一位将记录块内各项所需的位数，之后各项根据最大项所需的位数存储。这样，就实现了压缩存储的倒排索引。</p>
</li>
<li><p>Roaring Bitmaps</p>
<p>上述的 Frame of Reference 方法很好地解决了倒排索引在磁盘中的存储问题，而对于分块存储的倒排索引来说，需要频繁的求并集，面对多条件查询时还需要进行交集操作，对于快速的交并集操作，elastic search 采用了 Roaring Bitmaps 的方法，在缓存中进行压缩。</p>
<p>在介绍 Roaring Bitmaps 之前，我们先来介绍两种压缩方法：</p>
<ol>
<li><p>数组</p>
<p>也就是直接使用原始的文档 ID，进行数组操作，但这种方法显然不适合 elastic search 每次计算的数据量。</p>
</li>
<li><p>Bitmap</p>
<p>Bitmap 是一个常用的数据结构，我们通过一个例子来了解一下他的结构，我们现在有[2,3,5]和[1,3,4,5]两个数组，将其使用 Bitmap 来表示即为[0,0,1,1,0,1]和[0,1,0,1,1,1]，也就是原数组中的值所对应的 Bitmap 中相应脚标的值为 1，其余为 0。这样如果我们要对两个数组取交集，那么我们就对他们的 Bitmap 做与运算，取并集，就做或运算。</p>
</li>
</ol>
<p>我们看到 Bitmap 比较好地完成了对数组的压缩，无论原文档列表中各项的大小是多少，在 bitmap 中都只需要用一位的 0 或 1 来表示。事实上，相当长一段时间内，elastic search 都是采用这种方法的，直到 lucene5 开始使用 Roaring Bitmaps，这主要是为了解决 Bitmap 在稀疏情况下造成的空间浪费。</p>
<p>对于文档列表，使用 N/65536 得到该文档对应的块号，然后使用 N%65536 得到该文档在块内的 id，接下来根据不同的块号将文档分配的所属的块，最后根据块内文档数进行数组或位图的选择，这里的阈值来源于实际数据，当超过 4096 时选用位图，反之选用数组。</p>
</li>
</ol>
<h1 id="相关度计算"><a href="#相关度计算" class="headerlink" title="相关度计算"></a>相关度计算</h1><p>上一节中介绍的倒排索引让我们能够快速找到包含检索词的文档，但是当相关文档很多时，如果直接按照存储顺序呈现给用户，往往不会带来比较好的体验，我们需要计算文档与检索词的相关度，将最符合用户检索需求的结果排在靠前的位置。</p>
<p>为了进行相关度的计算，让我们先来了解几个参数</p>
<p>$$<br>词频：tf_{t \in d} = \sqrt{frequency}<br>$$</p>
<p>$$<br>逆向文档频率：idf_t = 1 + \log(\frac{numDocs}{docFreq+1})<br>$$</p>
<p>$$<br>字段长度归一值：norm_d = \frac{1}{\sqrt{numTerms}}<br>$$</p>
<p>其中：</p>
<ul>
<li>frequency：词 t 在文档 d 中出现的次数</li>
<li>numDocs：代表索引中文档数量</li>
<li>docFreq：代表包含词 t 的文档数</li>
<li>numTerms：代表所在字段的词数</li>
</ul>
<p>由此，相关度计算公式如下：</p>
<p>$$<br>score_{q,d} = coord_{(q,d)} * \sum_{t \in q}{tf_{t \in d} * idf_{t}^2 * Boost * norm_{(t,d)}}<br>$$</p>
<p>其中：</p>
<ul>
<li>$$<br>coord_{(q,d)}：\frac{文档中包含的查询词数}{查询词总数}<br>Boost：设定参数<br>$$</li>
</ul>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p>上一节中，我们已经根据词频等数据计算得到了各篇文档的相关度，接下来需要对其进行排序，大量数据表明，按相关度降序排序后的前 20 条结果可以满足大多数用户的一般查询需求。因此，通常情况下我们不需要将全部查询结果返回给用户，只需要将前 K 个最符合查询需求的记录返回给用户即可，这里的 K 通常为 20。</p>
<p>这也就是十分常见的<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/">topK 问题</a>，最基础的解法是将全部数据进行排序，然后取其前 K 个，但这种方法复杂度较高，在数据量比较大的时候并不适用。</p>
<p>一般来讲，我们采用最大堆/最小堆的方法，我们维护一个有前 k 个最大值构成的小顶堆，每拿到一个数据，就将其与堆顶数据比较，如果大于堆顶数据，则将堆顶数据删除，将新数据插入，反之则不做处理，这样当对全部数据遍历一遍后，堆中数据即为前 k 个最大值。若使用大顶堆，则开始遍历前对全部数据取反即可。</p>
<p>还可以使用快排的思想来解决 topK 问题，但实现过程较堆的过程相对复杂，故本文不做介绍，感兴趣的朋友可以自行探索。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>

  









    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2022 Xinrui Zhang
    
  </p>
</footer>
    
    
  </div>
</div>
</body>
</html>